{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Combination Attack Demo\n",
    "\n",
    "This is a demo of the Combination Attack, running on the E5 model, using the MSMARCO dataset, with 5 random queries."
   ],
   "id": "2912b0aba77ff05e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load model, datasets:",
   "id": "10f540ddf935a402"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from utils import data_utils\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/e5-base-v2\").to(device)\n",
    "print(\"Loaded E5 model.\")\n",
    "\n",
    "corpus, queries, _, _ = data_utils.load_dataset(\n",
    "    dataset_name=\"msmarco\",\n",
    "    data_split=\"dev\",\n",
    "    embedder_model_name=\"intfloat/e5-base-v2\",\n",
    ")\n",
    "print(\"Loaded MSMARCO dataset.\")\n",
    "\n",
    "local_results_path = hf_hub_download(\n",
    "    repo_id=\"MatanBT/retrieval-datasets-similarities\",\n",
    "    filename=\"msmarco-test_1.0_e5-base-v2_cos_sim.json\",\n",
    "    repo_type=\"dataset\",\n",
    ")\n",
    "with open(local_results_path) as f:\n",
    "    results = json.load(f)\n",
    "print(\"Loaded HF results.\")\n",
    "\n",
    "toxic_prefixes = [\n",
    "    row[\"text\"]\n",
    "    for row in load_dataset(\"toxigen/toxigen-data\")[\"train\"]\n",
    "    if row[\"toxicity_ai\"] == 5 and 50 < len(row[\"text\"]) < 100\n",
    "]\n",
    "print(\"Loaded ToxiGen dataset.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initiate variables:",
   "id": "10142a79555c3366"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trials = 5\n",
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "chosen_qids = np.random.choice(list(queries.keys()), size=(trials,), replace=False)\n",
    "chosen_poisons = np.random.choice(toxic_prefixes, size=(trials,), replace=False)\n",
    "\n",
    "info_rankings = []\n",
    "stuffing_rankings = []\n",
    "adv_rankings = []\n",
    "\n",
    "best_similarities = []\n",
    "info_similarities = []\n",
    "stuffing_similarities = []\n",
    "adv_similarities = []"
   ],
   "id": "372f141b0cdf38df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Perform attacks:",
   "id": "2c321d45df29244f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from attack import BlackBoxAttack\n",
    "\n",
    "\n",
    "def calc_ranking(sim, qid, results):\n",
    "    ranking = 0\n",
    "    for pid, score in results[qid].items():\n",
    "        if score > sim:\n",
    "            ranking += 1\n",
    "    return ranking\n",
    "\n",
    "\n",
    "for i, qid in enumerate(tqdm(chosen_qids)):\n",
    "    print(f\"Trial number {i + 1}\")\n",
    "\n",
    "    best_pid = list(results[qid].keys())[0]\n",
    "\n",
    "    # original passage and query\n",
    "    q = queries[qid]\n",
    "    print(f\"{qid}: {q}\")\n",
    "    p = corpus[best_pid][\"text\"]\n",
    "    print(f\"{best_pid}: {p}\")\n",
    "    info = \"passage: \" + chosen_poisons[i].strip()\n",
    "    print(f\"info: {info}\")\n",
    "\n",
    "    # batch encodings (except adv which depends on attack)\n",
    "    base_texts = [\n",
    "        q,\n",
    "        p,\n",
    "        info,\n",
    "        info + \" \" + q.replace(\"query: \", \"\"),\n",
    "    ]  # q, best passage, info, stuffing\n",
    "    with torch.inference_mode():\n",
    "        encs = model.encode(base_texts, convert_to_tensor=True)\n",
    "    q_enc, p_enc, info_enc, stuffing_enc = encs\n",
    "\n",
    "    # calculate similarities\n",
    "    best_sim = util.cos_sim(q_enc, p_enc).item()\n",
    "    print(f\"Similarity between query and original best passage: {best_sim}\")\n",
    "    info_sim = util.cos_sim(q_enc, info_enc).item()\n",
    "    print(f\"Similarity between query and info passage: {info_sim}\")\n",
    "    stuffing_sim = util.cos_sim(q_enc, stuffing_enc).item()\n",
    "    print(f\"Similarity between query and stuffing passage: {stuffing_sim}\")\n",
    "\n",
    "    # store similarities\n",
    "    best_similarities.append(best_sim)\n",
    "    info_similarities.append(info_sim)\n",
    "    stuffing_similarities.append(stuffing_sim)\n",
    "\n",
    "    # store rankings\n",
    "    info_rankings.append(calc_ranking(info_sim, qid, results))\n",
    "    stuffing_rankings.append(calc_ranking(stuffing_sim, qid, results))\n",
    "\n",
    "    # perform attack\n",
    "    print(\"Performing black-box attack...\")\n",
    "    bb_attack = BlackBoxAttack(model, q, sim=util.cos_sim)\n",
    "    tokens, _, _ = bb_attack.combination_attack(\n",
    "        info,\n",
    "        p_init=0.3946,\n",
    "        total_tokens=72,\n",
    "        num_iters=2940,\n",
    "        random_pool_per_pos=316,\n",
    "    )\n",
    "\n",
    "    # craft adversarial passage\n",
    "    p_adv = info + \" \" + \" \".join(tokens)\n",
    "    print(f\"adversarial: {p_adv}\")\n",
    "\n",
    "    # calculate adv similarity\n",
    "    with torch.inference_mode():\n",
    "        p_adv_enc = model.encode(p_adv, convert_to_tensor=True)\n",
    "    adv_sim = util.cos_sim(q_enc, p_adv_enc).item()\n",
    "    print(f\"Similarity between query and attacked passage: {adv_sim}\")\n",
    "\n",
    "    # store adv similarity and ranking\n",
    "    adv_similarities.append(adv_sim)\n",
    "    adv_rankings.append(calc_ranking(adv_sim, qid, results))\n",
    "\n",
    "    print(\"\\n\", flush=True)"
   ],
   "id": "183b1829d999d62c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Summarize results:",
   "id": "f396620db4f56d11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"Rankings of original passages: {info_rankings}\")\n",
    "print(f\"Rankings of stuffing passages: {stuffing_rankings}\")\n",
    "print(f\"Rankings of attacked passages: {adv_rankings}\")\n",
    "print(f\"Average ranking of attacked passages: {sum(adv_rankings) / trials}\")\n",
    "print(f\"Top 1 in {sum(r == 0 for r in adv_rankings)} out of {trials} attacks!\")\n",
    "print(f\"Top 5 in {sum(r < 5 for r in adv_rankings)} out of {trials} attacks!\")\n",
    "print(f\"Top 10 in {sum(r < 10 for r in adv_rankings)} out of {trials} attacks!\")\n",
    "\n",
    "print()\n",
    "print(f\"Similarities of best passages: {best_similarities}\")\n",
    "print(f\"Similarities of original passages: {info_similarities}\")\n",
    "print(f\"Similarities of stuffing passages: {stuffing_similarities}\")\n",
    "print(f\"Similarities of attacked passages: {adv_similarities}\")\n",
    "print(f\"Average similarity of attacked passages: {sum(adv_similarities) / trials}\")"
   ],
   "id": "c69073a986712a50",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
